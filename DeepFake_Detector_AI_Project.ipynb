{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faheemshahid8017/DeepFake-Detector_AI_Project/blob/main/DeepFake_Detector_AI_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXmZ8svCOGyR",
        "outputId": "d2387735-d88f-4ce1-db7f-2269b299e6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v73pMTbWOlTz"
      },
      "outputs": [],
      "source": [
        "!mkdir templates\n",
        "!mkdir uploads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwrOJcKNOrYS",
        "outputId": "df65b6a2-cfde-4591-add0-874ac9ae4070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile train.py\n",
        "import os\n",
        "import zipfile\n",
        "import urllib3\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models  # type: ignore\n",
        "from tensorflow.keras.layers import LeakyReLU  # type: ignore\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint  # type: ignore\n",
        "\n",
        "\n",
        "class DatasetHandler:\n",
        "    \"\"\"\n",
        "    A class to handle dataset downloading, unzipping, loading, and processing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_url, dataset_download_dir, dataset_file, dataset_dir, train_dir, test_dir, val_dir):\n",
        "        \"\"\"\n",
        "        Initialize the DatasetHandler with the specified parameters.\n",
        "\n",
        "        Args:\n",
        "            dataset_url (str): URL to download the dataset from.\n",
        "            dataset_download_dir (str): Directory to download the dataset to.\n",
        "            dataset_file (str): Name of the dataset file.\n",
        "            dataset_dir (str): Directory containing the dataset.\n",
        "            train_dir (str): Directory containing the training data.\n",
        "            test_dir (str): Directory containing the test data.\n",
        "            val_dir (str): Directory containing the validation data.\n",
        "        \"\"\"\n",
        "        self.dataset_url = dataset_url\n",
        "        self.dataset_download_dir = dataset_download_dir\n",
        "        self.dataset_file = dataset_file\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.train_dir = train_dir\n",
        "        self.test_dir = test_dir\n",
        "        self.val_dir = val_dir\n",
        "\n",
        "    def download_dataset(self):\n",
        "        \"\"\"\n",
        "        Download the dataset from the specified URL.\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the dataset was successfully downloaded, False otherwise.\n",
        "        \"\"\"\n",
        "        if not os.path.exists(self.dataset_download_dir):\n",
        "            os.makedirs(self.dataset_download_dir)\n",
        "        file_path = os.path.join(self.dataset_download_dir, self.dataset_file)\n",
        "        if os.path.exists(file_path):\n",
        "            print(f'dataset file {self.dataset_file} already exists at {file_path}')\n",
        "            return True\n",
        "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "        response = requests.get(self.dataset_url, stream=True, verify=False)\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "        with open(file_path, 'wb') as file, tqdm(desc=self.dataset_file, total=total_size, unit='iB', unit_scale=True, unit_divisor=1024) as bar:\n",
        "            for data in response.iter_content(chunk_size=1024):\n",
        "                size = file.write(data)\n",
        "                bar.update(size)\n",
        "        print(f'dataset downloaded and saved to {file_path}')\n",
        "        return True\n",
        "\n",
        "    def unzip_dataset(self):\n",
        "        \"\"\"\n",
        "        Unzip the downloaded dataset file.\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the dataset was successfully unzipped, False otherwise.\n",
        "        \"\"\"\n",
        "        file_path = os.path.join(self.dataset_download_dir, self.dataset_file)\n",
        "        if os.path.exists(self.dataset_dir):\n",
        "            print(f'dataset is already downloaded and extracted at {self.dataset_dir}')\n",
        "            return True\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f'dataset file {file_path} not found after download')\n",
        "            return False\n",
        "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.dataset_download_dir)\n",
        "        print(f'dataset extracted to {self.dataset_dir}')\n",
        "        return True\n",
        "\n",
        "    def get_image_dataset_from_directory(self, dir_name):\n",
        "        \"\"\"\n",
        "        Load image dataset from the specified directory.\n",
        "\n",
        "        Args:\n",
        "            dir_name (str): Name of the directory containing the dataset.\n",
        "\n",
        "        Returns:\n",
        "            tf.data.Dataset: Loaded image dataset.\n",
        "        \"\"\"\n",
        "        dir_path = os.path.join(self.dataset_dir, dir_name)\n",
        "        return tf.keras.utils.image_dataset_from_directory(\n",
        "            dir_path,\n",
        "            labels='inferred',\n",
        "            color_mode='rgb',\n",
        "            seed=42,\n",
        "            batch_size=64,\n",
        "            image_size=(128, 128)\n",
        "        )\n",
        "\n",
        "    def load_split_data(self):\n",
        "        \"\"\"\n",
        "        Load and split the dataset into training, validation, and test datasets.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Training, validation, and test datasets.\n",
        "        \"\"\"\n",
        "        train_data = self.get_image_dataset_from_directory(self.train_dir)\n",
        "        test_data = self.get_image_dataset_from_directory(self.test_dir)\n",
        "        val_data = self.get_image_dataset_from_directory(self.val_dir)\n",
        "        return train_data, test_data, val_data\n",
        "\n",
        "\n",
        "class DeepfakeDetectorModel:\n",
        "    \"\"\"\n",
        "    A class to create and train a deepfake detection model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the DeepfakeDetectorModel by building the model.\n",
        "        \"\"\"\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        \"\"\"\n",
        "        Build the deepfake detection model architecture.\n",
        "\n",
        "        Returns:\n",
        "            tf.keras.Model: Built model.\n",
        "        \"\"\"\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Input(shape=(128, 128, 3)))\n",
        "        model.add(layers.Rescaling(1./127, name='rescaling'))\n",
        "        model.add(layers.Conv2D(32, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "        model.add(layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "        model.add(layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(512, activation='relu'))\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(256, activation='relu'))\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation='relu'))\n",
        "        model.add(layers.Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "    def compile_model(self, learning_rate):\n",
        "        \"\"\"\n",
        "        Compile the deepfake detection model.\n",
        "\n",
        "        Args:\n",
        "            learning_rate (float): Learning rate for the optimizer.\n",
        "        \"\"\"\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        self.model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
        "        )\n",
        "\n",
        "    def train_model(self, train_data, val_data, epochs):\n",
        "        \"\"\"\n",
        "        Train the deepfake detection model.\n",
        "\n",
        "        Args:\n",
        "            train_data (tf.data.Dataset): Training dataset.\n",
        "            val_data (tf.data.Dataset): Validation dataset.\n",
        "            epochs (int): Number of epochs to train the model.\n",
        "\n",
        "        Returns:\n",
        "            tf.keras.callbacks.History: History object containing training details.\n",
        "        \"\"\"\n",
        "        early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1)\n",
        "        model_checkpoint_callback = ModelCheckpoint('deepfake_detector_model_best.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "        return self.model.fit(\n",
        "            train_data,\n",
        "            validation_data=val_data,\n",
        "            epochs=epochs,\n",
        "            callbacks=[early_stopping_callback, reduce_lr_callback, model_checkpoint_callback]\n",
        "        )\n",
        "\n",
        "    def evaluate_model(self, test_data):\n",
        "        \"\"\"\n",
        "        Evaluate the deepfake detection model.\n",
        "\n",
        "        Args:\n",
        "            test_data (tf.data.Dataset): Test dataset.\n",
        "\n",
        "        Returns:\n",
        "            list: Evaluation metrics.\n",
        "        \"\"\"\n",
        "        return self.model.evaluate(test_data)\n",
        "\n",
        "    def save_model(self, path):\n",
        "        \"\"\"\n",
        "        Save the deepfake detection model to the specified path.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to save the model.\n",
        "        \"\"\"\n",
        "        self.model.save(path)\n",
        "\n",
        "\n",
        "class TrainModel:\n",
        "    \"\"\"\n",
        "    A class to manage training of a deepfake detection model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_url, dataset_download_dir, dataset_file, dataset_dir, train_dir, test_dir, val_dir):\n",
        "        \"\"\"\n",
        "        Initialize the TrainModel class with the specified parameters.\n",
        "\n",
        "        Args:\n",
        "            dataset_url (str): URL to download the dataset from.\n",
        "            dataset_download_dir (str): Directory to download the dataset to.\n",
        "            dataset_file (str): Name of the dataset file.\n",
        "            dataset_dir (str): Directory containing the dataset.\n",
        "            train_dir (str): Directory containing the training data.\n",
        "            test_dir (str): Directory containing the test data.\n",
        "            val_dir (str): Directory containing the validation data.\n",
        "        \"\"\"\n",
        "        self.dataset_handler = DatasetHandler(dataset_url, dataset_download_dir, dataset_file, dataset_dir, train_dir, test_dir, val_dir)\n",
        "\n",
        "    def run_training(self, learning_rate=0.0001, epochs=50):\n",
        "        \"\"\"\n",
        "        Run the training process for the deepfake detection model.\n",
        "\n",
        "        Args:\n",
        "            learning_rate (float): Learning rate for the optimizer.\n",
        "            epochs (int): Number of epochs to train the model.\n",
        "\n",
        "        Returns:\n",
        "            tuple: History object and evaluation metrics.\n",
        "        \"\"\"\n",
        "        if not self.dataset_handler.download_dataset():\n",
        "            print('failed to download dataset')\n",
        "            return\n",
        "        if not self.dataset_handler.unzip_dataset():\n",
        "            print('failed to unzip dataset')\n",
        "            return\n",
        "        train_data, test_data, val_data = self.dataset_handler.load_split_data()\n",
        "        model = DeepfakeDetectorModel()\n",
        "        model.compile_model(learning_rate)\n",
        "        history = model.train_model(train_data, val_data, epochs)\n",
        "        evaluation_metrics = model.evaluate_model(test_data)\n",
        "        model.save_model('deepfake_detector_model.keras')\n",
        "        return history, evaluation_metrics\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # config\n",
        "    dataset_url = 'https://www.kaggle.com/api/v1/datasets/download/manjilkarki/deepfake-and-real-images?datasetVersionNumber=1'\n",
        "    dataset_download_dir = './data'\n",
        "    dataset_file = 'dataset.zip'\n",
        "    dataset_dir = './data/Dataset'\n",
        "    train_dir = 'Train'\n",
        "    test_dir = 'Test'\n",
        "    val_dir = 'Validation'\n",
        "\n",
        "    # instantiate the TrainModel class with the specified configuration\n",
        "    trainer = TrainModel(\n",
        "        dataset_url=dataset_url,\n",
        "        dataset_download_dir=dataset_download_dir,\n",
        "        dataset_file=dataset_file,\n",
        "        dataset_dir=dataset_dir,\n",
        "        train_dir=train_dir,\n",
        "        test_dir=test_dir,\n",
        "        val_dir=val_dir\n",
        "    )\n",
        "\n",
        "    # train\n",
        "    history, evaluation_metrics = trainer.run_training(learning_rate=0.0001, epochs=50)\n",
        "\n",
        "    # metrics\n",
        "    print('evaluation metrics:', evaluation_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5Y3XQ3iO0RJ",
        "outputId": "d6515a37-39b3-47eb-bc27-2bea750e176e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing inference.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile inference.py\n",
        "from flask import Flask, request, render_template\n",
        "from tensorflow.keras.models import load_model # type: ignore\n",
        "from tensorflow.keras.preprocessing import image # type: ignore\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class InferenceModel:\n",
        "    \"\"\"\n",
        "    A class to load a trained model and handle file uploads for predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_path):\n",
        "        \"\"\"\n",
        "        Initialize the InferenceModel class.\n",
        "\n",
        "        Args:\n",
        "            model_path (str): Path to the saved Keras model.\n",
        "        \"\"\"\n",
        "        self.model = load_model(model_path)\n",
        "        self.app = Flask(__name__)\n",
        "        self.app.config['UPLOAD_FOLDER'] = 'uploads'\n",
        "        self.model_path = model_path\n",
        "\n",
        "        @self.app.route('/', methods=['GET', 'POST'])\n",
        "        def upload_file():\n",
        "            \"\"\"\n",
        "            Handle file upload and prediction requests.\n",
        "\n",
        "            Returns:\n",
        "            --------\n",
        "            str\n",
        "                The rendered HTML template with the result or error message.\n",
        "            \"\"\"\n",
        "            if request.method == 'POST':\n",
        "                # check if the post request has the file part\n",
        "                if 'file' not in request.files:\n",
        "                    return render_template('index.html', error='no file part')\n",
        "                file = request.files['file']\n",
        "                # if user does not select file, browser also\n",
        "                # submit an empty part without filename\n",
        "                if file.filename == '':\n",
        "                    return render_template('index.html', error='no selected file')\n",
        "                if file and self.allowed_file(file.filename):\n",
        "                    # save the uploaded file to the uploads directory\n",
        "                    filename = os.path.join(self.app.config['UPLOAD_FOLDER'], file.filename)\n",
        "                    file.save(filename)\n",
        "                    # predict if the image is Real or Fake\n",
        "                    prediction, prediction_percentage = self.predict_image(filename)\n",
        "                    # clean up the uploaded file\n",
        "                    os.remove(filename)\n",
        "                    # determine result message\n",
        "                    result = 'Fake' if prediction >= 0.5 else 'Real'\n",
        "                    # render result to the user\n",
        "                    return render_template('index.html', result=result, prediction_percentage=prediction_percentage)\n",
        "                else:\n",
        "                    return render_template('index.html', error='allowed file types are png, jpg, jpeg')\n",
        "            return render_template('index.html')\n",
        "\n",
        "    def allowed_file(self, filename):\n",
        "        \"\"\"\n",
        "        Check if a file has an allowed extension.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        filename : str\n",
        "            The name of the file to check.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        bool\n",
        "            True if the file has an allowed extension, False otherwise.\n",
        "        \"\"\"\n",
        "        ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n",
        "        return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "    def predict_image(self, file_path):\n",
        "        \"\"\"\n",
        "        Predict whether an image is Real or Fake using the loaded model.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        file_path : str\n",
        "            The path to the image file.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        tuple\n",
        "            A tuple containing the prediction and the prediction percentage.\n",
        "        \"\"\"\n",
        "        img = image.load_img(file_path, target_size=(128, 128))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        result = self.model.predict(img_array)\n",
        "        prediction = result[0][0]\n",
        "        prediction_percentage = prediction * 100\n",
        "        return prediction, prediction_percentage\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Run the Flask application with the loaded model.\n",
        "        \"\"\"\n",
        "        self.app.run(debug=True)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # inference\n",
        "    model_path = 'deepfake_detector_model.keras'\n",
        "    inference_model = InferenceModel(model_path)\n",
        "    inference_model.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzFufNR1O5s-",
        "outputId": "b1c56526-5824-4c2c-d39b-a1d2eb5a4feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing templates/index.html\n"
          ]
        }
      ],
      "source": [
        "%%writefile templates/index.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Deepfake Detector</title>\n",
        "    <!-- Bootstrap CSS -->\n",
        "    <link href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1 class=\"mt-4\">Deepfake Detector</h1>\n",
        "\n",
        "        <form method=\"POST\" enctype=\"multipart/form-data\" class=\"mt-4\">\n",
        "            <div class=\"form-group\">\n",
        "                <input type=\"file\" name=\"file\" class=\"form-control-file\">\n",
        "            </div>\n",
        "            <button type=\"submit\" class=\"btn btn-primary\">Upload</button>\n",
        "        </form>\n",
        "\n",
        "        {% if error %}\n",
        "            <div class=\"alert alert-danger mt-4\" role=\"alert\">\n",
        "                {{ error }}\n",
        "            </div>\n",
        "        {% endif %}\n",
        "\n",
        "        {% if result %}\n",
        "            <div class=\"alert alert-success mt-4\" role=\"alert\">\n",
        "                <p><strong>Result:</strong> {{ result }}</p>\n",
        "                <p><strong>Prediction Percentage:</strong> {{ prediction_percentage }}%</p>\n",
        "            </div>\n",
        "        {% endif %}\n",
        "    </div>\n",
        "\n",
        "    <!-- Bootstrap JS and dependencies -->\n",
        "    <script src=\"https://code.jquery.com/jquery-3.5.1.slim.min.js\"></script>\n",
        "    <script src=\"https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.4/dist/umd/popper.min.js\"></script>\n",
        "    <script src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js\"></script>\n",
        "</body>\n",
        "</html>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Lnk_BwPBKr",
        "outputId": "aad76b0d-959b-4a05-e35b-a7ba4d0d1bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flask numpy matplotlib opencv-python scikit-learn pandas tqdm requests\n",
        "# TensorFlow already Colab mein hai, extra install nahi karna\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXrx83PMPH3D",
        "outputId": "5e04de5e-509a-428a-af8f-0822d4452ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-21 18:03:51.043867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769018631.074870     774 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769018631.084285     774 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769018631.106891     774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769018631.106926     774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769018631.106934     774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769018631.106941     774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "dataset.zip: 100% 1.68G/1.68G [00:25<00:00, 70.6MiB/s]\n",
            "dataset downloaded and saved to ./data/dataset.zip\n",
            "dataset extracted to ./data/Dataset\n",
            "Found 140002 files belonging to 2 classes.\n",
            "2026-01-21 18:05:10.647519: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1769018710.649051     774 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Found 10905 files belonging to 2 classes.\n",
            "Found 39428 files belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "2026-01-21 18:05:17.247200: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1769018718.714068    1147 service.cc:152] XLA service 0x7e36f4004110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1769018718.714100    1147 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1769018719.506351    1147 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1769018726.975275    1147 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7425 - loss: 0.5255 - precision: 0.7336 - recall: 0.75962026-01-21 18:07:45.843045: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n",
            "2026-01-21 18:07:45.893689: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.23750, saving model to deepfake_detector_model_best.keras\n",
            "2026-01-21 18:07:45.972813: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n",
            "2026-01-21 18:07:46.079432: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 33554432 exceeds 10% of free system memory.\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 64ms/step - accuracy: 0.7426 - loss: 0.5255 - precision: 0.7336 - recall: 0.7596 - val_accuracy: 0.9018 - val_loss: 0.2375 - val_precision: 0.9405 - val_recall: 0.8586 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9390 - loss: 0.1532 - precision: 0.9359 - recall: 0.9423\n",
            "Epoch 2: val_loss improved from 0.23750 to 0.17408, saving model to deepfake_detector_model_best.keras\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 68ms/step - accuracy: 0.9390 - loss: 0.1532 - precision: 0.9359 - recall: 0.9423 - val_accuracy: 0.9254 - val_loss: 0.1741 - val_precision: 0.8961 - val_recall: 0.9630 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m1738/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.9593 - loss: 0.1033 - precision: 0.9555 - recall: 0.9632"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te-yBWidgOGT"
      },
      "outputs": [],
      "source": [
        "!cp deepfake_detector_model.keras /content/drive/MyDrive/deepfake_model.keras\n",
        "print(\"Model saved to Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9od3p2o_gYBM"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wyfi68KgiT3"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "# Purane tunnels band karo\n",
        "!killall ngrok 2>/dev/null\n",
        "# Flask app background mein chalao\n",
        "get_ipython().system_raw('python inference.py &')\n",
        "# Public URL banao\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"ðŸŽ‰ Browser mein ye URL kholo aur images test karo:\")\n",
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4axtE8RiKge"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"37bz9imiRzSwkvbctYxFSNeqWJd_7ZCFKvKLb39C4hQKh8u7s\")  # quotes ke andar paste karo, quotes hatao mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WopPU6-JiTGb"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "!killall ngrok 2>/dev/null\n",
        "get_ipython().system_raw('python inference.py &')\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"ðŸŽ‰ Browser mein ye URL kholo:\")\n",
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkmWrytFMf9m"
      },
      "outputs": [],
      "source": [
        "!pip install mtcnn opencv-python reportlab tensorflow tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQiTmP_sMtfP"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"debajyatidey/faceforensics-videos-cropped-faces\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuUtWPFjQdCe"
      },
      "outputs": [],
      "source": [
        "!pip install mtcnn opencv-python reportlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQaQh33aQhzC"
      },
      "outputs": [],
      "source": [
        "def download_ffpp_dataset():\n",
        "    # Download latest version from KaggleHub\n",
        "    path = kagglehub.dataset_download(\"debajyatidey/faceforensics-videos-cropped-faces\")\n",
        "    print(\"Path to dataset files:\", path)\n",
        "\n",
        "    # âš ï¸ Do NOT try to create folders inside /kaggle/input (read-only)\n",
        "    # Just return the dataset path\n",
        "    return path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSWa7Gm7RvJ6"
      },
      "outputs": [],
      "source": [
        "def load_dataset(base_path, split='train', batch_size=32):\n",
        "    path = os.path.join(base_path, split)\n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        path,\n",
        "        labels='inferred',\n",
        "        label_mode='binary',\n",
        "        batch_size=batch_size,\n",
        "        image_size=(128, 128),\n",
        "        seed=42,\n",
        "        color_mode='rgb'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4Wr8l2HR-ig"
      },
      "outputs": [],
      "source": [
        "import os, shutil, glob\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import Xception, EfficientNetB0\n",
        "\n",
        "# === DATASET ===\n",
        "def download_ffpp_dataset():\n",
        "    path = kagglehub.dataset_download(\"debajyatidey/faceforensics-videos-cropped-faces\")\n",
        "    print(\"Path to dataset files:\", path)\n",
        "    return path\n",
        "\n",
        "def prepare_dataset(base_path, train_split=0.7, val_split=0.15, test_split=0.15):\n",
        "    \"\"\"Split dataset into train/val/test inside /kaggle/working\"\"\"\n",
        "    working_path = \"/kaggle/working/ffpp_frames\"\n",
        "    os.makedirs(working_path, exist_ok=True)\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        os.makedirs(os.path.join(working_path, split), exist_ok=True)\n",
        "\n",
        "    # assume dataset has subfolders per class (e.g., 'real', 'fake')\n",
        "    classes = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
        "    for cls in classes:\n",
        "        files = glob.glob(os.path.join(base_path, cls, \"*.jpg\"))\n",
        "        n = len(files)\n",
        "        train_end = int(train_split * n)\n",
        "        val_end = int((train_split + val_split) * n)\n",
        "\n",
        "        splits = {\n",
        "            \"train\": files[:train_end],\n",
        "            \"val\": files[train_end:val_end],\n",
        "            \"test\": files[val_end:]\n",
        "        }\n",
        "\n",
        "        for split, split_files in splits.items():\n",
        "            cls_dir = os.path.join(working_path, split, cls)\n",
        "            os.makedirs(cls_dir, exist_ok=True)\n",
        "            for f in split_files:\n",
        "                shutil.copy(f, cls_dir)\n",
        "\n",
        "    return working_path\n",
        "\n",
        "def load_dataset(base_path, split='train', batch_size=32):\n",
        "    path = os.path.join(base_path, split)\n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        path,\n",
        "        labels='inferred',\n",
        "        label_mode='binary',\n",
        "        batch_size=batch_size,\n",
        "        image_size=(128, 128),\n",
        "        seed=42,\n",
        "        color_mode='rgb'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqcv94asSQDK"
      },
      "outputs": [],
      "source": [
        "import shutil, glob\n",
        "\n",
        "def prepare_dataset(base_path, train_split=0.7, val_split=0.15, test_split=0.15):\n",
        "    \"\"\"Split dataset into train/val/test inside /kaggle/working\"\"\"\n",
        "    working_path = \"/kaggle/working/ffpp_frames\"\n",
        "    os.makedirs(working_path, exist_ok=True)\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        os.makedirs(os.path.join(working_path, split), exist_ok=True)\n",
        "\n",
        "    # assume dataset has subfolders per class (e.g., 'real', 'fake')\n",
        "    classes = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
        "    for cls in classes:\n",
        "        files = glob.glob(os.path.join(base_path, cls, \"*.jpg\"))\n",
        "        n = len(files)\n",
        "        train_end = int(train_split * n)\n",
        "        val_end = int((train_split + val_split) * n)\n",
        "\n",
        "        splits = {\n",
        "            \"train\": files[:train_end],\n",
        "            \"val\": files[train_end:val_end],\n",
        "            \"test\": files[val_end:]\n",
        "        }\n",
        "\n",
        "        for split, split_files in splits.items():\n",
        "            cls_dir = os.path.join(working_path, split, cls)\n",
        "            os.makedirs(cls_dir, exist_ok=True)\n",
        "            for f in split_files:\n",
        "                shutil.copy(f, cls_dir)\n",
        "\n",
        "    return working_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkBtzesuS72G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"/kaggle/input/faceforensics-videos-cropped-faces\"\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    print(root, dirs[:5], files[:5])  # show first few entries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYkjnbcaTW74"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"/kaggle/input/faceforensics-videos-cropped-faces\"\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    if files:\n",
        "        print(root, files[:5])  # show first 5 files in each folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykJRHtzDT19T"
      },
      "outputs": [],
      "source": [
        "def load_dataset(base_path, split='train', batch_size=32):\n",
        "    path = os.path.join(base_path, split)\n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        path,\n",
        "        labels='inferred',\n",
        "        label_mode='binary',\n",
        "        batch_size=batch_size,\n",
        "        image_size=(128, 128),\n",
        "        seed=42,\n",
        "        color_mode='rgb'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jldX8HXlXDJz"
      },
      "outputs": [],
      "source": [
        "%pip install mtcnn[tensorflow]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjO4awh-YKNL"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import os, glob\n",
        "import cv2\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T60xb94iYPP1"
      },
      "outputs": [],
      "source": [
        "base_path = r'/kaggle/input/ff-c23/FaceForensics++_C23/'\n",
        "\n",
        "ffpp_real = sorted(glob.glob(os.path.join(base_path, 'original', '*.mp4')))\n",
        "ffpp_fake = sorted(glob.glob(os.path.join(base_path, 'Deepfakes', '*.mp4')))\n",
        "video_paths = {'real': ffpp_real, 'fake': ffpp_fake}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLzSRMSWYX_w"
      },
      "outputs": [],
      "source": [
        "print(f'No. of fake videos,- {len(video_paths[\"fake\"])}')\n",
        "print(f'No. of real videos,- {len(video_paths[\"real\"])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tSAapPFYd00"
      },
      "outputs": [],
      "source": [
        "def extract_iframes(video_path, output_dir, num_frames=10):\n",
        "    \"\"\"\n",
        "    Extract equidistant frames from a video using cv2.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to input video file.\n",
        "        output_dir (str): Directory where frames will be saved.\n",
        "        num_frames (int): Number of frames to extract.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Error opening video: {video_path}\")\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # If requested frames > available, limit it\n",
        "    num_frames = min(num_frames, total_frames)\n",
        "\n",
        "    step = total_frames // num_frames\n",
        "\n",
        "    frame_ids = [i * step for i in range(num_frames)]\n",
        "\n",
        "    for idx, frame_id in enumerate(frame_ids):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            frame_filename = os.path.join(output_dir, f\"frame_{idx:04d}.png\")\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "        else:\n",
        "            print(f\"Warning: could not read frame {frame_id} in {video_path}\")\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Extracted {len(frame_ids)} frames from {video_path}\")\n",
        "    frames = sorted(glob.glob(os.path.join(output_dir, \"frame_*.png\")))\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTZnaVkFYi5l"
      },
      "outputs": [],
      "source": [
        "from mtcnn import MTCNN\n",
        "from mtcnn.utils.images import load_image\n",
        "def crop_faces_mtcnn(image_paths, output_dir, detector=None):\n",
        "    \"\"\"\n",
        "    Crops the highest-confidence face from each image using MTCNN.\n",
        "    Returns a list of saved cropped face image paths.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    if detector is None:\n",
        "        detector = MTCNN()\n",
        "\n",
        "    cropped_files = []\n",
        "    for img_path in image_paths:\n",
        "        img = load_image(img_path)\n",
        "        results = detector.detect_faces(img)\n",
        "        if not results:\n",
        "            continue\n",
        "\n",
        "        best_face = max(results, key=lambda x: x['confidence'])\n",
        "        conf = best_face['confidence']\n",
        "\n",
        "        x, y, w, h = best_face['box']\n",
        "        x, y = max(0, x), max(0, y)\n",
        "        face_crop = img[y:y+h, x:x+w]\n",
        "\n",
        "        tensor = tf.cast(face_crop, tf.uint8)  # must be uint8 for encoding\n",
        "        encoded = tf.image.encode_png(tensor)\n",
        "        out_file = os.path.join(output_dir, os.path.basename(img_path))\n",
        "        tf.io.write_file(out_file, encoded)\n",
        "        cropped_files.append(out_file)\n",
        "\n",
        "    return cropped_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4vnilGTYlt2"
      },
      "outputs": [],
      "source": [
        "def extract_faces_from_video(video_path, work_dir):\n",
        "    \"\"\"\n",
        "    Complete pipeline: extracts Keyframes from a video, then crops faces with MTCNN.\n",
        "    Returns list of cropped face image paths.\n",
        "    \"\"\"\n",
        "    base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    frames_dir = os.path.join(work_dir, f\"{base_name}_frames\")\n",
        "    crops_dir = os.path.join(work_dir, f\"{base_name}_crops\")\n",
        "\n",
        "    # Step 1: Extract Keyframes\n",
        "    frames = extract_iframes(video_path, frames_dir)\n",
        "\n",
        "    # Step 2: Crop faces\n",
        "    detector = MTCNN()\n",
        "    cropped_faces = crop_faces_mtcnn(frames, crops_dir, detector=detector)\n",
        "\n",
        "    return cropped_faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz-gWTGIYpBX"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "for label in video_paths:\n",
        "    print(f'\\nExtracting and Cropping {label} videos\\n')\n",
        "    out_dir = f\"/kaggle/working/{label}/\"\n",
        "    for video_path in video_paths[label]:\n",
        "        cropped_faces = extract_faces_from_video(video_path,out_dir)\n",
        "        print(f\"Extracted and cropped {len(cropped_faces)} faces from {video_path}\")\n",
        "        gc.collect()\n",
        "        !rm -rf /kaggle/working/*/*_frames/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3VXEzZNZslw"
      },
      "outputs": [],
      "source": [
        "!pip install mtcnn opencv-python reportlab tensorflow tensorflow_hub kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTlRQqI-Z2Cl"
      },
      "outputs": [],
      "source": [
        "# %%writefile train.py\n",
        "import os\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import Xception, EfficientNetB0\n",
        "\n",
        "# === DATASET: FaceForensics++ Cropped Faces (Public Kaggle Dataset) ===\n",
        "def download_ffpp_cropped_dataset():\n",
        "    # Download the dataset using kagglehub\n",
        "    print(\"Downloading FF++ Cropped Faces dataset...\")\n",
        "    path = kagglehub.dataset_download(\"debajyatidey/faceforensics-videos-cropped-faces\")\n",
        "    print(f\"Dataset downloaded to: {path}\")\n",
        "    return path\n",
        "\n",
        "def load_dataset(dataset_path, split='train', batch_size=32):\n",
        "    \"\"\"Load dataset from the specified directory.\"\"\"\n",
        "    path = os.path.join(dataset_path, split)\n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        path,\n",
        "        labels='inferred',\n",
        "        label_mode='binary',\n",
        "        batch_size=batch_size,\n",
        "        image_size=(128, 128),\n",
        "        seed=42,\n",
        "        color_mode='rgb'\n",
        "    )\n",
        "\n",
        "# === MODELS ===\n",
        "def build_custom_cnn():\n",
        "    model = models.Sequential([\n",
        "        layers.Input((128, 128, 3)),\n",
        "        layers.Rescaling(1./127.5, offset=-1),\n",
        "        layers.Conv2D(32, 3, activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, activation='relu'),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_xception():\n",
        "    base = Xception(weights='imagenet', include_top=False, input_shape=(128,128,3))\n",
        "    base.trainable = False\n",
        "    model = models.Sequential([\n",
        "        layers.Rescaling(1./127.5, offset=-1),\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_efficientnet():\n",
        "    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(128,128,3))\n",
        "    base.trainable = False\n",
        "    model = models.Sequential([\n",
        "        layers.Rescaling(1./127.5, offset=-1),\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# === TRAINING ===\n",
        "def train_model(model, name, train_ds, val_ds, epochs=20):\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=5, restore_best_weights=True),\n",
        "        ModelCheckpoint(f\"{name}_best.keras\", save_best_only=True)\n",
        "    ]\n",
        "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n",
        "    model.save(f\"{name}.keras\")\n",
        "    return history\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Authenticate Kaggle (using your provided key)\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        # Create kaggle.json with your key\n",
        "        with open('kaggle.json', 'w') as f:\n",
        "            f.write('{\"username\":\"your_username\",\"key\":\"KGAT_3ac23225afad9972c5f6d2cc6bc41220\"}')\n",
        "        !mkdir -p ~/.kaggle\n",
        "        !cp kaggle.json ~/.kaggle/\n",
        "        !chmod 600 ~/.kaggle/kaggle.json\n",
        "        print(\"Kaggle authenticated successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Kaggle authentication failed: {e}\")\n",
        "\n",
        "    # Download FF++ dataset\n",
        "    dataset_path = download_ffpp_cropped_dataset()\n",
        "\n",
        "    # Load datasets\n",
        "    train_ds = load_dataset(dataset_path, 'train', 32).prefetch(tf.data.AUTOTUNE)\n",
        "    val_ds = load_dataset(dataset_path, 'val', 32).prefetch(tf.data.AUTOTUNE)\n",
        "    test_ds = load_dataset(dataset_path, 'test', 32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Train models\n",
        "    for model_fn, name in [(build_custom_cnn, \"custom_cnn\"),\n",
        "                           (build_xception, \"xception\"),\n",
        "                           (build_efficientnet, \"efficientnet\")]:\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        model = model_fn()\n",
        "        train_model(model, name, train_ds, val_ds, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4giv96EVbVXi"
      },
      "outputs": [],
      "source": [
        "!ls /kaggle/input/faceforensics-videos-cropped-faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlDozwPdd8Ho"
      },
      "outputs": [],
      "source": [
        "# %%writefile train.py\n",
        "import os\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import Xception, EfficientNetB0\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# === DATASET: FaceForensics++ Cropped Faces ===\n",
        "def download_ffpp_cropped_dataset():\n",
        "    print(\"Downloading FF++ Cropped Faces dataset...\")\n",
        "    path = kagglehub.dataset_download(\"debajyatidey/faceforensics-videos-cropped-faces\")\n",
        "    print(f\"Dataset downloaded to: {path}\")\n",
        "    return path\n",
        "\n",
        "def load_and_split_dataset(dataset_path, batch_size=32, val_split=0.15, test_split=0.15):\n",
        "    \"\"\"\n",
        "    Load the entire dataset and split it into train/val/test.\n",
        "    Assumes root directory has 'real/' and 'fake/' subfolders.\n",
        "    \"\"\"\n",
        "    full_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        labels='inferred',\n",
        "        label_mode='binary',\n",
        "        batch_size=None,  # No batching yet\n",
        "        image_size=(128, 128),\n",
        "        seed=42,\n",
        "        color_mode='rgb'\n",
        "    )\n",
        "\n",
        "    # Convert to lists for splitting\n",
        "    images, labels = [], []\n",
        "    for img, lbl in full_ds:\n",
        "        images.append(img.numpy())\n",
        "        labels.append(lbl.numpy())\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # First split: train + (val + test)\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        images, labels, test_size=(val_split + test_split), random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    # Second split: val and test\n",
        "    val_ratio = val_split / (val_split + test_split)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=(1 - val_ratio), random_state=42, stratify=y_temp\n",
        "    )\n",
        "\n",
        "    # Convert back to tf.data.Dataset\n",
        "    def make_dataset(X, y, batch_size):\n",
        "        ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "        return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    train_ds = make_dataset(X_train, y_train, batch_size)\n",
        "    val_ds = make_dataset(X_val, y_val, batch_size)\n",
        "    test_ds = make_dataset(X_test, y_test, batch_size)\n",
        "\n",
        "    return train_ds, val_ds, test_ds\n",
        "\n",
        "# === MODELS ===\n",
        "def build_custom_cnn():\n",
        "    model = models.Sequential([\n",
        "        layers.Input((128, 128, 3)),\n",
        "        layers.Rescaling(1./127.5, offset=-1),\n",
        "        layers.Conv2D(32, 3, activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, activation='relu'),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_xception():\n",
        "    base = Xception(weights='imagenet', include_top=False, input_shape=(128,128,3))\n",
        "    base.trainable = False\n",
        "    model = models.Sequential([\n",
        "        layers.Rescaling(1./127.5, offset=-1),\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_efficientnet():\n",
        "    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(128,128,3))\n",
        "    base.trainable = False\n",
        "    model = models.Sequential([\n",
        "        layers.Rescaling(1./127.5, offset=-1),\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# === TRAINING ===\n",
        "def train_model(model, name, train_ds, val_ds, epochs=20):\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=5, restore_best_weights=True),\n",
        "        ModelCheckpoint(f\"{name}_best.keras\", save_best_only=True)\n",
        "    ]\n",
        "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n",
        "    model.save(f\"{name}.keras\")\n",
        "    return history\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Authenticate Kaggle\n",
        "    try:\n",
        "        with open('kaggle.json', 'w') as f:\n",
        "            f.write('{\"username\":\"your_username\",\"key\":\"KGAT_3ac23225afad9972c5f6d2cc6bc41220\"}')\n",
        "        !mkdir -p ~/.kaggle\n",
        "        !cp kaggle.json ~/.kaggle/\n",
        "        !chmod 600 ~/.kaggle/kaggle.json\n",
        "        print(\"Kaggle authenticated successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Kaggle authentication skipped: {e}\")\n",
        "\n",
        "    # Download FF++ dataset\n",
        "    dataset_path = download_ffpp_cropped_dataset()\n",
        "\n",
        "    # Load and split dataset\n",
        "    print(\"Loading and splitting dataset...\")\n",
        "    train_ds, val_ds, test_ds = load_and_split_dataset(dataset_path, batch_size=32)\n",
        "\n",
        "    # Train models\n",
        "    for model_fn, name in [(build_custom_cnn, \"custom_cnn\"),\n",
        "                           (build_xception, \"xception\"),\n",
        "                           (build_efficientnet, \"efficientnet\")]:\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        model = model_fn()\n",
        "        train_model(model, name, train_ds, val_ds, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUyhmDFYe8s5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4Im1OBge8y6"
      },
      "outputs": [],
      "source": [
        "# %%writefile autonomous_agent.py\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime\n",
        "from mtcnn import MTCNN\n",
        "from tensorflow.keras.models import load_model\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfbase import pdfmetrics\n",
        "from reportlab.pdfbase.ttfonts import TTFont\n",
        "\n",
        "# Initialize MTCNN\n",
        "detector = MTCNN()\n",
        "\n",
        "def extract_frames(video_path, max_frames=30):\n",
        "    \"\"\"Extract up to `max_frames` from a video.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    if total == 0:\n",
        "        cap.release()\n",
        "        return frames  # Empty video\n",
        "    step = max(1, total // max_frames)\n",
        "    count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if count % step == 0:\n",
        "            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        count += 1\n",
        "    cap.release()\n",
        "    return frames[:max_frames]\n",
        "\n",
        "def detect_and_crop_face(img):\n",
        "    \"\"\"Detect the largest face in an image and crop it.\"\"\"\n",
        "    faces = detector.detect_faces(img)\n",
        "    if not faces:\n",
        "        return None\n",
        "    # Sort by face area (largest first)\n",
        "    faces = sorted(faces, key=lambda x: x['box'][2] * x['box'][3], reverse=True)\n",
        "    x, y, w, h = faces[0]['box']\n",
        "    x, y = max(0, x), max(0, y)\n",
        "    cropped = img[y:y+h, x:x+w]\n",
        "    return cv2.resize(cropped, (128, 128))\n",
        "\n",
        "def load_models():\n",
        "    \"\"\"Load all trained models.\"\"\"\n",
        "    models = {}\n",
        "    for name in [\"custom_cnn\", \"xception\", \"efficientnet\"]:\n",
        "        model_path = f\"{name}_best.keras\"\n",
        "        if os.path.exists(model_path):\n",
        "            try:\n",
        "                models[name] = load_model(model_path)\n",
        "                print(f\"Loaded model: {name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load {name}: {e}\")\n",
        "    return models\n",
        "\n",
        "def predict_on_image(img, models):\n",
        "    \"\"\"Predict on a single image using the best available model.\"\"\"\n",
        "    img = np.expand_dims(img.astype('float32') / 127.5 - 1, axis=0)\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        pred = model.predict(img, verbose=0)[0][0]\n",
        "        results[name] = float(pred)\n",
        "\n",
        "    # Select the best model (Xception preferred for FF++)\n",
        "    if \"xception\" in results:\n",
        "        final = results[\"xception\"]\n",
        "        model_used = \"Xception\"\n",
        "    elif \"efficientnet\" in results:\n",
        "        final = results[\"efficientnet\"]\n",
        "        model_used = \"EfficientNet-B0\"\n",
        "    elif \"custom_cnn\" in results:\n",
        "        final = results[\"custom_cnn\"]\n",
        "        model_used = \"Custom CNN\"\n",
        "    else:\n",
        "        raise ValueError(\"No valid models loaded!\")\n",
        "\n",
        "    return final, model_used, results\n",
        "\n",
        "def generate_pdf_report(report_data, pdf_path):\n",
        "    \"\"\"Generate a forensic PDF report with Colab-safe fonts.\"\"\"\n",
        "    try:\n",
        "        # Register a standard font to avoid Colab issues\n",
        "        from reportlab.pdfbase.pdfmetrics import registerFont\n",
        "        from reportlab.pdfbase.ttfonts import TTFont\n",
        "        # Use a built-in font\n",
        "        c = canvas.Canvas(pdf_path, pagesize=letter)\n",
        "\n",
        "        # Title\n",
        "        c.setFont(\"Helvetica-Bold\", 16)\n",
        "        c.drawString(100, 750, \"Deepfake Forensic Report\")\n",
        "\n",
        "        # Details\n",
        "        c.setFont(\"Helvetica\", 12)\n",
        "        c.drawString(100, 730, f\"File: {report_data.get('filename', 'N/A')}\")\n",
        "        c.drawString(100, 710, f\"Result: {'FAKE' if report_data['is_fake'] else 'REAL'}\")\n",
        "        c.drawString(100, 690, f\"Confidence: {report_data['confidence']:.2%}\")\n",
        "        c.drawString(100, 670, f\"Model Used: {report_data['model_used']}\")\n",
        "        c.drawString(100, 650, f\"Analysis Time: {report_data['timestamp']}\")\n",
        "\n",
        "        if 'frame_count' in report_data:\n",
        "            c.drawString(100, 630, f\"Frames Analyzed: {report_data['frame_count']}\")\n",
        "            c.drawString(100, 610, f\"Frame Confidence Std Dev: {report_data.get('std_dev', 0):.4f}\")\n",
        "\n",
        "        c.save()\n",
        "        print(f\"PDF report saved to: {pdf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"PDF generation failed: {e}\")\n",
        "        # Fallback: just create an empty file to avoid crashing\n",
        "        with open(pdf_path, 'w') as f:\n",
        "            f.write(\"PDF generation failed due to Colab environment limitations.\")\n",
        "\n",
        "def run_agent(file_path):\n",
        "    \"\"\"Main function to run the autonomous agent.\"\"\"\n",
        "    is_video = file_path.lower().endswith(('.mp4', '.avi', '.mov', '.webm'))\n",
        "    models = load_models()\n",
        "\n",
        "    if not models:\n",
        "        return {\"error\": \"No trained models found. Please run train.py first.\"}\n",
        "\n",
        "    if is_video:\n",
        "        print(\"Processing video...\")\n",
        "        frames = extract_frames(file_path)\n",
        "        if not frames:\n",
        "            return {\"error\": \"No frames extracted from video. Invalid or corrupted file.\"}\n",
        "\n",
        "        predictions = []\n",
        "        for i, frame in enumerate(frames):\n",
        "            face = detect_and_crop_face(frame)\n",
        "            if face is not None:\n",
        "                pred, model_used, _ = predict_on_image(face, models)\n",
        "                predictions.append(pred)\n",
        "            # Optional: Add progress indicator\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"Processed {i+1}/{len(frames)} frames...\")\n",
        "\n",
        "        if not predictions:\n",
        "            return {\"error\": \"No faces detected in video\"}\n",
        "\n",
        "        avg_conf = np.mean(predictions)\n",
        "        std_conf = np.std(predictions)\n",
        "        is_fake = avg_conf >= 0.5\n",
        "\n",
        "        result = {\n",
        "            \"file_type\": \"video\",\n",
        "            \"filename\": os.path.basename(file_path),\n",
        "            \"model_used\": model_used,\n",
        "            \"is_fake\": bool(is_fake),\n",
        "            \"confidence\": float(avg_conf),\n",
        "            \"std_dev\": float(std_conf),\n",
        "            \"frame_count\": len(predictions),\n",
        "            \"frame_predictions\": [float(p) for p in predictions],\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "    else:\n",
        "        print(\"Processing image...\")\n",
        "        img = cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
        "        if img is None:\n",
        "            return {\"error\": \"Invalid image file. Could not load.\"}\n",
        "\n",
        "        face = detect_and_crop_face(img)\n",
        "        if face is None:\n",
        "            return {\"error\": \"No face detected in image\"}\n",
        "\n",
        "        pred, model_used, all_preds = predict_on_image(face, models)\n",
        "        result = {\n",
        "            \"file_type\": \"image\",\n",
        "            \"filename\": os.path.basename(file_path),\n",
        "            \"model_used\": model_used,\n",
        "            \"is_fake\": bool(pred >= 0.5),\n",
        "            \"confidence\": float(pred),\n",
        "            \"all_model_predictions\": all_preds,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "    # Generate JSON report\n",
        "    json_path = file_path + \"_report.json\"\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(result, f, indent=2)\n",
        "\n",
        "    # Generate PDF report\n",
        "    pdf_path = file_path + \"_report.pdf\"\n",
        "    generate_pdf_report(result, pdf_path)\n",
        "\n",
        "    result[\"json_report\"] = json_path\n",
        "    result[\"pdf_report\"] = pdf_path\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENSphC0LfcG0"
      },
      "outputs": [],
      "source": [
        "!pip install mtcnn opencv-python reportlab tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7DwFBtjfiLi"
      },
      "outputs": [],
      "source": [
        "# %%writefile train_additional_models.py\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import Xception, EfficientNetB0\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Load your existing dataset (same structure as your current train.py)\n",
        "def load_split_data():\n",
        "    def load_dir(name):\n",
        "        return tf.keras.utils.image_dataset_from_directory(\n",
        "            f'./data/Dataset/{name}',\n",
        "            labels='inferred',\n",
        "            label_mode='binary',\n",
        "            batch_size=32,\n",
        "            image_size=(128, 128),\n",
        "            seed=42\n",
        "        )\n",
        "    return load_dir('Train'), load_dir('Validation'), load_dir('Test')\n",
        "\n",
        "def build_xception():\n",
        "    base = Xception(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "    base.trainable = False\n",
        "    return models.Sequential([\n",
        "        layers.Rescaling(1./127.5, offset=-1),\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "def build_efficientnet():\n",
        "    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "    base.trainable = False\n",
        "    return models.Sequential([\n",
        "        layers.Rescaling(1./127.5, offset=-1),\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "def train_and_save(model_fn, name):\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    train, val, _ = load_split_data()\n",
        "    model = model_fn()\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=5, restore_best_weights=True),\n",
        "        ModelCheckpoint(f'{name}_best.keras', save_best_only=True)\n",
        "    ]\n",
        "    model.fit(train, validation_data=val, epochs=20, callbacks=callbacks)\n",
        "    model.save(f'{name}.keras')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_save(build_xception, \"xception\")\n",
        "    train_and_save(build_efficientnet, \"efficientnet\")\n",
        "    print(\"\\nâœ… Xception & EfficientNet training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYvKyaOmf45s"
      },
      "outputs": [],
      "source": [
        "# %%writefile autonomous_agent.py\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime\n",
        "from mtcnn import MTCNN\n",
        "from tensorflow.keras.models import load_model\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import letter\n",
        "\n",
        "detector = MTCNN()\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def extract_frames(video_path, max_frames=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames, total = [], int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    if total == 0: return frames\n",
        "    step = max(1, total // max_frames)\n",
        "    for i in range(total):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        if i % step == 0:\n",
        "            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        if len(frames) >= max_frames: break\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "def detect_and_crop_face(img):\n",
        "    faces = detector.detect_faces(img)\n",
        "    if not faces: return None\n",
        "    x, y, w, h = max(faces, key=lambda f: f['box'][2]*f['box'][3])['box']\n",
        "    x, y = max(0, x), max(0, y)\n",
        "    return cv2.resize(img[y:y+h, x:x+w], (128, 128))\n",
        "\n",
        "def load_all_models():\n",
        "    models = {}\n",
        "    # Try loading proposal-compliant models first\n",
        "    for name in [\"xception\", \"efficientnet\"]:\n",
        "        if os.path.exists(f\"{name}_best.keras\"):\n",
        "            models[name] = load_model(f\"{name}_best.keras\")\n",
        "    # Fallback to your original model\n",
        "    if not models and os.path.exists(\"deepfake_detector_model.keras\"):\n",
        "        models[\"custom_cnn\"] = load_model(\"deepfake_detector_model.keras\")\n",
        "    return models\n",
        "\n",
        "def predict_image(img, models):\n",
        "    img = np.expand_dims(img.astype('float32') / 127.5 - 1, axis=0)\n",
        "    preds = {name: float(model.predict(img, verbose=0)[0][0]) for name, model in models.items()}\n",
        "    # Select best model (proposal priority: Xception > EfficientNet > Custom)\n",
        "    if \"xception\" in preds:\n",
        "        final, model_used = preds[\"xception\"], \"Xception\"\n",
        "    elif \"efficientnet\" in preds:\n",
        "        final, model_used = preds[\"efficientnet\"], \"EfficientNet-B0\"\n",
        "    else:\n",
        "        final, model_used = preds[\"custom_cnn\"], \"Custom CNN\"\n",
        "    return final, model_used, preds\n",
        "\n",
        "def generate_pdf_report(data, path):\n",
        "    c = canvas.Canvas(path, pagesize=letter)\n",
        "    c.drawString(100, 750, \"Deepfake Forensic Report\")\n",
        "    c.drawString(100, 730, f\"File: {data['filename']}\")\n",
        "    c.drawString(100, 710, f\"Result: {'FAKE' if data['is_fake'] else 'REAL'}\")\n",
        "    c.drawString(100, 690, f\"Confidence: {data['confidence']:.2%}\")\n",
        "    c.drawString(100, 670, f\"Model Used: {data['model_used']}\")\n",
        "    c.save()\n",
        "\n",
        "# --- Main Agent Function ---\n",
        "def run_autonomous_agent(file_path):\n",
        "    is_video = file_path.lower().endswith(('.mp4', '.avi', '.mov'))\n",
        "    models = load_all_models()\n",
        "    if not models:\n",
        "        return {\"error\": \"No models found!\"}\n",
        "\n",
        "    if is_video:\n",
        "        frames = extract_frames(file_path)\n",
        "        preds = []\n",
        "        for frame in frames:\n",
        "            face = detect_and_crop_face(frame)\n",
        "            if face is not None:\n",
        "                pred, model_used, _ = predict_image(face, models)\n",
        "                preds.append(pred)\n",
        "        if not preds:\n",
        "            return {\"error\": \"No faces detected in video\"}\n",
        "        avg_conf = np.mean(preds)\n",
        "        result = {\n",
        "            \"file_type\": \"video\",\n",
        "            \"filename\": os.path.basename(file_path),\n",
        "            \"model_used\": model_used,\n",
        "            \"is_fake\": bool(avg_conf >= 0.5),\n",
        "            \"confidence\": float(avg_conf),\n",
        "            \"frame_count\": len(preds),\n",
        "            \"std_dev\": float(np.std(preds))\n",
        "        }\n",
        "    else:\n",
        "        img = cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
        "        face = detect_and_crop_face(img)\n",
        "        if face is None:\n",
        "            return {\"error\": \"No face detected in image\"}\n",
        "        pred, model_used, all_preds = predict_image(face, models)\n",
        "        result = {\n",
        "            \"file_type\": \"image\",\n",
        "            \"filename\": os.path.basename(file_path),\n",
        "            \"model_used\": model_used,\n",
        "            \"is_fake\": bool(pred >= 0.5),\n",
        "            \"confidence\": float(pred)\n",
        "        }\n",
        "\n",
        "    # Save reports\n",
        "    json_path = file_path + \"_report.json\"\n",
        "    pdf_path = file_path + \"_report.pdf\"\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(result, f, indent=2)\n",
        "    generate_pdf_report(result, pdf_path)\n",
        "    result.update({\"json_report\": json_path, \"pdf_report\": pdf_path})\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLoRXfZXgANS"
      },
      "outputs": [],
      "source": [
        "# %%writefile inference.py\n",
        "from flask import Flask, request, render_template, send_file\n",
        "import os\n",
        "import tempfile\n",
        "from autonomous_agent import run_autonomous_agent\n",
        "\n",
        "app = Flask(__name__)\n",
        "os.makedirs(\"uploads\", exist_ok=True)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def upload_file():\n",
        "    if request.method == 'POST':\n",
        "        file = request.files.get('file')\n",
        "        if not file or file.filename == '':\n",
        "            return render_template('index.html', error='No file selected')\n",
        "        if not file.filename.lower().endswith(('.png', '.jpg', '.jpeg', '.mp4', '.avi', '.mov')):\n",
        "            return render_template('index.html', error='Invalid file type (use JPG/PNG/MP4/AVI)')\n",
        "\n",
        "        temp_path = os.path.join(tempfile.gettempdir(), file.filename)\n",
        "        file.save(temp_path)\n",
        "\n",
        "        try:\n",
        "            result = run_autonomous_agent(temp_path)\n",
        "            os.remove(temp_path)\n",
        "            if \"error\" in result:\n",
        "                return render_template('index.html', error=result[\"error\"])\n",
        "            return render_template('index.html',\n",
        "                result=\"Fake\" if result[\"is_fake\"] else \"Real\",\n",
        "                confidence=f\"{result['confidence']:.2%}\",\n",
        "                model=result[\"model_used\"],\n",
        "                pdf_report=os.path.basename(result[\"pdf_report\"])\n",
        "            )\n",
        "        except Exception as e:\n",
        "            return render_template('index.html', error=f\"Processing failed: {str(e)}\")\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/download/<filename>')\n",
        "def download_report(filename):\n",
        "    return send_file(os.path.join(tempfile.gettempdir(), filename), as_attachment=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axF94DRFgIpy"
      },
      "outputs": [],
      "source": [
        "<!-- templates/index.html -->\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <title>Autonomous Deepfake Detector</title>\n",
        "  <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"container mt-4\">\n",
        "  <h2>Autonomous Deepfake Forensic Agent</h2>\n",
        "  <form method=\"POST\" enctype=\"multipart/form-data\">\n",
        "    <div class=\"mb-3\">\n",
        "      <input class=\"form-control\" type=\"file\" name=\"file\" accept=\".jpg,.jpeg,.png,.mp4,.avi,.mov\" required>\n",
        "    </div>\n",
        "    <button class=\"btn btn-primary\" type=\"submit\">Analyze</button>\n",
        "  </form>\n",
        "\n",
        "  {% if error %}\n",
        "    <div class=\"alert alert-danger mt-3\">{{ error }}</div>\n",
        "  {% endif %}\n",
        "\n",
        "  {% if result %}\n",
        "    <div class=\"card mt-3\">\n",
        "      <div class=\"card-body\">\n",
        "        <h5 class=\"card-title\">Result: <span class=\"badge bg-{{ 'danger' if result=='Fake' else 'success' }}\">{{ result }}</span></h5>\n",
        "        <p>Confidence: <strong>{{ confidence }}</strong></p>\n",
        "        <p>Model Used: {{ model }}</p>\n",
        "        <a href=\"/download/{{ pdf_report }}\" class=\"btn btn-outline-secondary\">Download PDF Report</a>\n",
        "      </div>\n",
        "    </div>\n",
        "  {% endif %}\n",
        "</div>\n",
        "</body>\n",
        "</html>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkUCWoQIgLij"
      },
      "outputs": [],
      "source": [
        "!killall ngrok 2>/dev/null\n",
        "get_ipython().system_raw('python inference.py &')\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"37bz9imiRzSwkvbctYxFSNeqWJd_7ZCFKvKLb39C4hQKh8u7s\")\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"ðŸŒ Public URL: {public_url}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}